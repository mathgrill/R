### https://www.kaggle.com/c/nyc-taxi-trip-duration/data
# https://www.kaggle.com/headsortails/nyc-taxi-rides-eda

# https://stackoverflow.com/questions/33903883/r-extract-hours-from-time-in-factor-format
# https://stackoverflow.com/questions/18999710/creating-a-new-column-to-a-data-frame-using-a-formula-from-another-variable
# https://www.rdocumentation.org/packages/h2o/versions/3.8.3.3/topics/h2o.deeplearning
# https://stackoverflow.com/questions/3418128/how-to-convert-a-factor-to-an-integer-numeric-without-a-loss-of-information
# https://www.stat.berkeley.edu/~s133/dates.html
# https://stackoverflow.com/questions/32363998/function-to-calculate-geospatial-distance-between-two-points-lat-long-using-r
# http://www.statmethods.net/input/contents.html


train <- read.csv(file="train.csv",nrows=10000)

# installing a pkg
install.packages("data.table")
# load it
library(data.table)

# set working dir
setwd("/Volumes/WD-fat/R/NYCtrip")

# Step 2: Separate the dataset to 80% for training and 20% for testing
library (caret)
inTrain<- createDataPartition(train$trip_duration, p=0.8, list=FALSE)
training<-train[inTrain,]
testing<-train[-inTrain,]

#store the datasets into .csv files
write.csv (training , file = "train-data.csv", row.names = FALSE) 
write.csv (testing , file = "test-data.csv", row.names = FALSE)
nrow(training)
nrow(testing)

# Step 3: Load the h2o package

library(h2o)
 
# start a local h2o cluster
local.h2o <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, nthreads=-1)

# Load the training and testing datasets and convert the label to digit factor
training <- read.csv ("train-data.csv") 
testing  <- read.csv ("test-data.csv")

# pass dataframe from inside of the R environment to the H2O instance
trData<-as.h2o(training)
tsData<-as.h2o(testing)

# Step 4: Train the model

res.dl <- h2o.deeplearning(x = 6:10, y = 11, trData, activation = "Tanh", hidden=rep(160,5),epochs = 20)

# install package
install.packages("geosphere")
library(geosphere)
istm (c(lon1, lat1), c(lon2, lat2), fun = distHaversine)
library(dplyr)
# append the distance between the points to the training dataset
training <- training %>% mutate(CTD = distHaversine(cbind(pickup_longitude, pickup_latitude), cbind(dropoff_longitude, dropoff_latitude)))

# list columns
names(training)
# remove column 12
training <-training[,-c(12)]
# update csv files
write.csv(testing, file = "testing.csv", row.names=FALSE)
write.csv(training, file = "training.csv", row.names=FALSE)

# round distance CTD
testing$CTD <- round(testing$CTD, 0)
write.csv(testing, file = "testing.csv")
training$CTD <- round(training$CTD, 0)
write.csv(training, file = "training.csv")

res.dl <- h2o.deeplearning(x = c(6,7,8,9,10,12), y = 11, trData, activation = "Tanh", hidden=rep(160,5),epochs = 20)

test <- test %>% mutate(CTD = distHaversine(cbind(pickup_longitude, pickup_latitude), cbind(dropoff_longitude, dropoff_latitude)))
write.csv(test, file = "test.csv", row.names=FALSE)

# make predictions
pred.dl<-h2o.predict(object=res.dl, newdata=test_h2o)
summary(pred.dl)
df.test <- as.data.frame(pred.dl)
write.csv(df.test, file = "submission3.csv")

# new iteration take into account start of the trip and day of the week
training$day <- weekdays(as.Date(training$pickup_datetime))
training$hour <- format(strptime(training$pickup_datetime,"%Y-%m-%d %H:%M:%S"),'%H')

test$day <- weekdays(as.Date(test$pickup_datetime))
test$hour <- format(strptime(test$pickup_datetime,"%Y-%m-%d %H:%M:%S"),'%H')
head(training, n=10)
head(test, n=10)

training$hour <- as.numeric(training$hour)
training$day <- as.factor(training$day)

test$hour <- as.numeric(test$hour)
test$day <- as.factor(test$day)

# pass test data to h2o 
test_h2o<-as.h2o(test)

res.dl <- h2o.deeplearning(x = c(6,7,8,9,10,12,13,14), y = 11, trData, activation = "Tanh", hidden=rep(160,5),epochs = 20)
